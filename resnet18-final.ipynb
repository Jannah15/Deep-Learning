{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":269359,"sourceType":"datasetVersion","datasetId":111880}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\nfrom torch.utils.tensorboard import SummaryWriter\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport seaborn as sns\nimport pandas as pd\nimport time\nimport os\nfrom tqdm import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-02T12:58:20.538977Z","iopub.execute_input":"2025-05-02T12:58:20.539485Z","iopub.status.idle":"2025-05-02T12:58:20.544239Z","shell.execute_reply.started":"2025-05-02T12:58:20.539462Z","shell.execute_reply":"2025-05-02T12:58:20.543442Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Set random seeds for reproducibility\ntorch.manual_seed(42)\nnp.random.seed(42)\nIMAGE_SIZE = (150, 150)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T12:58:45.405685Z","iopub.execute_input":"2025-05-02T12:58:45.406323Z","iopub.status.idle":"2025-05-02T12:58:45.412910Z","shell.execute_reply.started":"2025-05-02T12:58:45.406297Z","shell.execute_reply":"2025-05-02T12:58:45.412113Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Paths to dataset\nDATA_DIR = \"/kaggle/input/intel-image-classification/seg_train/seg_train\"\nVAL_DIR = \"/kaggle/input/intel-image-classification/seg_test/seg_test\"\n\n# Preprocessing\ntransform = transforms.Compose([\n    transforms.Resize(IMAGE_SIZE),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                        std=[0.229, 0.224, 0.225])\n])\n\n# Create datasets\ntrain_dataset = datasets.ImageFolder(DATA_DIR, transform=transform)\nval_dataset = datasets.ImageFolder(VAL_DIR, transform=transform)\n\n# Create dataloaders\nBATCH_SIZE = 64\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T12:58:46.064241Z","iopub.execute_input":"2025-05-02T12:58:46.064595Z","iopub.status.idle":"2025-05-02T12:58:52.980262Z","shell.execute_reply.started":"2025-05-02T12:58:46.064543Z","shell.execute_reply":"2025-05-02T12:58:52.979618Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Basic ResNet Block\nclass BasicBlock(nn.Module):\n    expansion = 1  # For BasicBlock, expansion is always 1\n\n    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n        super().__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n\n        self.relu = nn.ReLU(inplace=True)\n\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n\n        self.downsample = downsample\n\n    def forward(self, x):\n        identity = x\n\n        out = self.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n\n        if self.downsample:\n            identity = self.downsample(x)\n\n        out += identity\n        out = self.relu(out)\n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T12:58:55.292969Z","iopub.execute_input":"2025-05-02T12:58:55.293307Z","iopub.status.idle":"2025-05-02T12:58:55.300133Z","shell.execute_reply.started":"2025-05-02T12:58:55.293280Z","shell.execute_reply":"2025-05-02T12:58:55.299220Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# ResNet18 Model\nclass ResNet18(nn.Module):\n    def __init__(self, num_classes=6):\n        super().__init__()\n\n        self.in_channels = 64\n\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n        self.layer1 = self._make_layer(BasicBlock, 64, 2, stride=1)\n        self.layer2 = self._make_layer(BasicBlock, 128, 2, stride=2)\n        self.layer3 = self._make_layer(BasicBlock, 256, 2, stride=2)\n        self.layer4 = self._make_layer(BasicBlock, 512, 2, stride=2)\n\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n\n        self.fc = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(512 * BasicBlock.expansion, 128),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(128, num_classes)\n        )\n\n    def _make_layer(self, block, out_channels, blocks, stride):\n        downsample = None\n\n        if stride != 1 or self.in_channels != out_channels * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.in_channels, out_channels * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels * block.expansion)\n            )\n\n        layers = [block(self.in_channels, out_channels, stride, downsample)]\n        self.in_channels = out_channels * block.expansion\n\n        for _ in range(1, blocks):\n            layers.append(block(self.in_channels, out_channels))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.relu(self.bn1(self.conv1(x)))\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = self.fc(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T12:58:57.459093Z","iopub.execute_input":"2025-05-02T12:58:57.459904Z","iopub.status.idle":"2025-05-02T12:58:57.469112Z","shell.execute_reply.started":"2025-05-02T12:58:57.459878Z","shell.execute_reply":"2025-05-02T12:58:57.468237Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Initialize TensorBoard writers\ncurrent_time = time.strftime(\"%Y%m%d-%H%M%S\")\nadam_writer = SummaryWriter(f'runs/ResNet18_Adam_{current_time}')\nsgd_writer = SummaryWriter(f'runs/ResNet18_SGD_{current_time}')\n\n# Initialize device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T12:58:59.674854Z","iopub.execute_input":"2025-05-02T12:58:59.675173Z","iopub.status.idle":"2025-05-02T12:58:59.741451Z","shell.execute_reply.started":"2025-05-02T12:58:59.675148Z","shell.execute_reply":"2025-05-02T12:58:59.740802Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Define two variants with different hyperparameters\nvariants = [\n    {\n        'name': 'ResNet18_Adam',\n        'optimizer': 'adam',\n        'lr': 0.001,\n        'weight_decay': 0.0001,\n        'scheduler': True,\n        'writer': adam_writer\n    },\n    {\n        'name': 'ResNet18_SGD',\n        'optimizer': 'sgd',\n        'lr': 0.01,\n        'momentum': 0.9,\n        'weight_decay': 0.001,\n        'scheduler': True,\n        'writer': sgd_writer\n    }\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T12:59:01.428640Z","iopub.execute_input":"2025-05-02T12:59:01.429417Z","iopub.status.idle":"2025-05-02T12:59:01.433722Z","shell.execute_reply.started":"2025-05-02T12:59:01.429384Z","shell.execute_reply":"2025-05-02T12:59:01.432865Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def train_model(model, train_loader, val_loader, optimizer, criterion, scheduler, device, num_epochs, variant):\n    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n    best_acc = 0.0\n    best_model_wts = None\n\n    for epoch in range(num_epochs):\n        # Training\n        model.train()\n        running_loss, correct, total = 0.0, 0, 0\n        for batch_idx, (inputs, targets) in enumerate(tqdm(train_loader, desc=f\"{variant['name']} - Epoch {epoch+1}/{num_epochs} [Training]\")):\n            inputs, targets = inputs.to(device), targets.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += targets.size(0)\n            correct += predicted.eq(targets).sum().item()\n\n            # TensorBoard batch metrics\n            global_step = epoch * len(train_loader) + batch_idx\n            variant['writer'].add_scalar('Batch/Train_Loss', loss.item(), global_step)\n            variant['writer'].add_scalar('Batch/Train_Accuracy', 100. * correct / total, global_step)\n\n        train_loss = running_loss / len(train_loader)\n        train_acc = 100. * correct / total\n        history['train_loss'].append(train_loss)\n        history['train_acc'].append(train_acc)\n\n        # Validation (no report here)\n        model.eval()\n        val_loss, val_correct, val_total = 0.0, 0, 0\n        with torch.no_grad():\n            for inputs, targets in val_loader:\n                inputs, targets = inputs.to(device), targets.to(device)\n                outputs = model(inputs)\n                loss = criterion(outputs, targets)\n                val_loss += loss.item()\n                _, predicted = outputs.max(1)\n                val_total += targets.size(0)\n                val_correct += predicted.eq(targets).sum().item()\n\n        val_loss /= len(val_loader)\n        val_acc = 100. * val_correct / val_total\n        history['val_loss'].append(val_loss)\n        history['val_acc'].append(val_acc)\n\n        # TensorBoard epoch metrics\n        variant['writer'].add_scalar('Epoch/Train_Loss', train_loss, epoch)\n        variant['writer'].add_scalar('Epoch/Train_Accuracy', train_acc, epoch)\n        variant['writer'].add_scalar('Epoch/Val_Loss', val_loss, epoch)\n        variant['writer'].add_scalar('Epoch/Val_Accuracy', val_acc, epoch)\n\n        # Scheduler step\n        if scheduler:\n            scheduler.step(val_acc)\n\n        print(f\"{variant['name']} - Epoch {epoch+1}/{num_epochs}: \"\n              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% | \"\n              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n\n        if val_acc > best_acc:\n            best_acc = val_acc\n            best_model_wts = model.state_dict()\n            torch.save(best_model_wts, f\"best_{variant['name']}.pth\")\n            print(f\"New best model saved with val accuracy: {best_acc:.2f}%\")\n\n    model.load_state_dict(best_model_wts)\n    return model, history\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T12:59:03.088333Z","iopub.execute_input":"2025-05-02T12:59:03.089101Z","iopub.status.idle":"2025-05-02T12:59:03.099360Z","shell.execute_reply.started":"2025-05-02T12:59:03.089076Z","shell.execute_reply":"2025-05-02T12:59:03.098509Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def evaluate_model(model, loader, criterion, device, variant_name=\"model\"):\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    all_preds = []\n    all_targets = []\n\n    with torch.no_grad():\n        for inputs, targets in tqdm(loader, desc=f\"Evaluating {variant_name}\"):\n            inputs, targets = inputs.to(device), targets.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n\n            running_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += targets.size(0)\n            correct += predicted.eq(targets).sum().item()\n\n            all_preds.extend(predicted.cpu().numpy())\n            all_targets.extend(targets.cpu().numpy())\n\n    loss = running_loss / len(loader)\n    acc = 100. * correct / total\n\n    # Confusion matrix and classification report\n    cm = confusion_matrix(all_targets, all_preds)\n    report = classification_report(all_targets, all_preds, target_names=train_dataset.classes)\n\n    # Save confusion matrix\n    cm_df = pd.DataFrame(cm, index=train_dataset.classes, columns=train_dataset.classes)\n    plt.figure(figsize=(10, 7))\n    sns.heatmap(cm_df, annot=True, cmap='Blues', fmt='g')\n    plt.title(f'Confusion Matrix - {variant_name}')\n    plt.ylabel('True Label')\n    plt.xlabel('Predicted Label')\n    os.makedirs(\"confusion_matrices\", exist_ok=True)\n    filename = os.path.join(\"confusion_matrices\", f\"{variant_name}_confusion_matrix.png\")\n    plt.savefig(filename)\n    plt.close()\n\n    # Save report\n    os.makedirs(\"reports\", exist_ok=True)\n    with open(f\"reports/{variant_name}_classification_report.txt\", \"w\") as f:\n        f.write(report)\n\n    print(f\"Confusion matrix saved to {filename}\")\n    print(\"Classification Report:\")\n    print(report)\n\n    return loss, acc, all_preds, all_targets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T12:59:05.533006Z","iopub.execute_input":"2025-05-02T12:59:05.533672Z","iopub.status.idle":"2025-05-02T12:59:05.541305Z","shell.execute_reply.started":"2025-05-02T12:59:05.533648Z","shell.execute_reply":"2025-05-02T12:59:05.540502Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Train for each variant\n\nnum_epochs = 10\n\nfor variant in variants:\n    print(f\"\\nTraining with variant: {variant['name']}\")\n    \n    model = ResNet18(num_classes=6).to(device)\n    criterion = nn.CrossEntropyLoss()\n\n    optimizer = (\n        optim.Adam(model.parameters(), lr=variant['lr'], weight_decay=variant['weight_decay'])\n        if variant['optimizer'] == 'adam'\n        else optim.SGD(model.parameters(), lr=variant['lr'], momentum=variant['momentum'], weight_decay=variant['weight_decay'])\n    )\n\n    scheduler = (\n        optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=3, verbose=True)\n        if variant.get('scheduler')\n        else None\n    )\n\n    # TensorBoard writer (separate for each run)\n    log_dir = os.path.join(\"runs\", variant['name'])\n    os.makedirs(log_dir, exist_ok=True)\n    variant['writer'] = SummaryWriter(log_dir=log_dir)\n\n    # Train\n    model, history = train_model(model, train_loader, val_loader, optimizer, criterion, scheduler, device, num_epochs, variant)\n\n    # Final Evaluation\n    print(f\"\\nFinal evaluation for variant: {variant['name']}\")\n    evaluate_model(model, val_loader, criterion, device, variant_name=variant['name'])\n\n    variant['writer'].close()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T12:59:07.513737Z","iopub.execute_input":"2025-05-02T12:59:07.514791Z","iopub.status.idle":"2025-05-02T13:08:30.112628Z","shell.execute_reply.started":"2025-05-02T12:59:07.514757Z","shell.execute_reply":"2025-05-02T13:08:30.111765Z"}},"outputs":[{"name":"stdout","text":"\nTraining with variant: ResNet18_Adam\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\nResNet18_Adam - Epoch 1/10 [Training]: 100%|██████████| 220/220 [00:25<00:00,  8.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"ResNet18_Adam - Epoch 1/10: Train Loss: 0.9409, Train Acc: 62.38% | Val Loss: 0.7794, Val Acc: 69.97%\nNew best model saved with val accuracy: 69.97%\n","output_type":"stream"},{"name":"stderr","text":"ResNet18_Adam - Epoch 2/10 [Training]: 100%|██████████| 220/220 [00:26<00:00,  8.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"ResNet18_Adam - Epoch 2/10: Train Loss: 0.6958, Train Acc: 75.02% | Val Loss: 1.0838, Val Acc: 62.10%\n","output_type":"stream"},{"name":"stderr","text":"ResNet18_Adam - Epoch 3/10 [Training]: 100%|██████████| 220/220 [00:24<00:00,  8.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"ResNet18_Adam - Epoch 3/10: Train Loss: 0.6055, Train Acc: 78.17% | Val Loss: 0.5872, Val Acc: 77.63%\nNew best model saved with val accuracy: 77.63%\n","output_type":"stream"},{"name":"stderr","text":"ResNet18_Adam - Epoch 4/10 [Training]: 100%|██████████| 220/220 [00:24<00:00,  8.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"ResNet18_Adam - Epoch 4/10: Train Loss: 0.5639, Train Acc: 80.06% | Val Loss: 0.5216, Val Acc: 81.60%\nNew best model saved with val accuracy: 81.60%\n","output_type":"stream"},{"name":"stderr","text":"ResNet18_Adam - Epoch 5/10 [Training]: 100%|██████████| 220/220 [00:25<00:00,  8.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"ResNet18_Adam - Epoch 5/10: Train Loss: 0.5073, Train Acc: 81.90% | Val Loss: 0.5328, Val Acc: 80.77%\n","output_type":"stream"},{"name":"stderr","text":"ResNet18_Adam - Epoch 6/10 [Training]: 100%|██████████| 220/220 [00:25<00:00,  8.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"ResNet18_Adam - Epoch 6/10: Train Loss: 0.4761, Train Acc: 83.02% | Val Loss: 0.4421, Val Acc: 83.60%\nNew best model saved with val accuracy: 83.60%\n","output_type":"stream"},{"name":"stderr","text":"ResNet18_Adam - Epoch 7/10 [Training]: 100%|██████████| 220/220 [00:25<00:00,  8.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"ResNet18_Adam - Epoch 7/10: Train Loss: 0.4604, Train Acc: 84.15% | Val Loss: 0.5431, Val Acc: 81.23%\n","output_type":"stream"},{"name":"stderr","text":"ResNet18_Adam - Epoch 8/10 [Training]: 100%|██████████| 220/220 [00:24<00:00,  8.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"ResNet18_Adam - Epoch 8/10: Train Loss: 0.4372, Train Acc: 84.84% | Val Loss: 0.7003, Val Acc: 74.27%\n","output_type":"stream"},{"name":"stderr","text":"ResNet18_Adam - Epoch 9/10 [Training]: 100%|██████████| 220/220 [00:25<00:00,  8.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"ResNet18_Adam - Epoch 9/10: Train Loss: 0.4174, Train Acc: 85.55% | Val Loss: 1.3479, Val Acc: 59.17%\n","output_type":"stream"},{"name":"stderr","text":"ResNet18_Adam - Epoch 10/10 [Training]: 100%|██████████| 220/220 [00:25<00:00,  8.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"ResNet18_Adam - Epoch 10/10: Train Loss: 0.3960, Train Acc: 86.30% | Val Loss: 0.6118, Val Acc: 79.93%\n\nFinal evaluation for variant: ResNet18_Adam\n","output_type":"stream"},{"name":"stderr","text":"Evaluating ResNet18_Adam: 100%|██████████| 47/47 [00:02<00:00, 17.48it/s]\n/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Confusion matrix saved to confusion_matrices/ResNet18_Adam_confusion_matrix.png\nClassification Report:\n              precision    recall  f1-score   support\n\n   buildings       0.91      0.75      0.82       437\n      forest       0.95      0.97      0.96       474\n     glacier       0.82      0.44      0.58       553\n    mountain       0.58      0.94      0.72       525\n         sea       0.87      0.86      0.86       510\n      street       0.86      0.87      0.86       501\n\n    accuracy                           0.80      3000\n   macro avg       0.83      0.80      0.80      3000\nweighted avg       0.83      0.80      0.79      3000\n\n\nTraining with variant: ResNet18_SGD\n","output_type":"stream"},{"name":"stderr","text":"ResNet18_SGD - Epoch 1/10 [Training]: 100%|██████████| 220/220 [00:24<00:00,  8.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"ResNet18_SGD - Epoch 1/10: Train Loss: 0.9005, Train Acc: 65.38% | Val Loss: 0.8834, Val Acc: 69.07%\nNew best model saved with val accuracy: 69.07%\n","output_type":"stream"},{"name":"stderr","text":"ResNet18_SGD - Epoch 2/10 [Training]: 100%|██████████| 220/220 [00:24<00:00,  8.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"ResNet18_SGD - Epoch 2/10: Train Loss: 0.6028, Train Acc: 78.07% | Val Loss: 0.6592, Val Acc: 76.73%\nNew best model saved with val accuracy: 76.73%\n","output_type":"stream"},{"name":"stderr","text":"ResNet18_SGD - Epoch 3/10 [Training]: 100%|██████████| 220/220 [00:25<00:00,  8.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"ResNet18_SGD - Epoch 3/10: Train Loss: 0.5228, Train Acc: 81.30% | Val Loss: 0.6270, Val Acc: 77.37%\nNew best model saved with val accuracy: 77.37%\n","output_type":"stream"},{"name":"stderr","text":"ResNet18_SGD - Epoch 4/10 [Training]: 100%|██████████| 220/220 [00:24<00:00,  8.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"ResNet18_SGD - Epoch 4/10: Train Loss: 0.4718, Train Acc: 83.40% | Val Loss: 0.6656, Val Acc: 76.50%\n","output_type":"stream"},{"name":"stderr","text":"ResNet18_SGD - Epoch 5/10 [Training]: 100%|██████████| 220/220 [00:24<00:00,  8.94it/s]\n","output_type":"stream"},{"name":"stdout","text":"ResNet18_SGD - Epoch 5/10: Train Loss: 0.4263, Train Acc: 84.45% | Val Loss: 0.4915, Val Acc: 82.67%\nNew best model saved with val accuracy: 82.67%\n","output_type":"stream"},{"name":"stderr","text":"ResNet18_SGD - Epoch 6/10 [Training]: 100%|██████████| 220/220 [00:24<00:00,  8.94it/s]\n","output_type":"stream"},{"name":"stdout","text":"ResNet18_SGD - Epoch 6/10: Train Loss: 0.3883, Train Acc: 86.73% | Val Loss: 0.5321, Val Acc: 82.27%\n","output_type":"stream"},{"name":"stderr","text":"ResNet18_SGD - Epoch 7/10 [Training]: 100%|██████████| 220/220 [00:24<00:00,  8.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"ResNet18_SGD - Epoch 7/10: Train Loss: 0.3761, Train Acc: 86.94% | Val Loss: 0.4464, Val Acc: 84.00%\nNew best model saved with val accuracy: 84.00%\n","output_type":"stream"},{"name":"stderr","text":"ResNet18_SGD - Epoch 8/10 [Training]: 100%|██████████| 220/220 [00:24<00:00,  8.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"ResNet18_SGD - Epoch 8/10: Train Loss: 0.3485, Train Acc: 87.74% | Val Loss: 0.4414, Val Acc: 84.60%\nNew best model saved with val accuracy: 84.60%\n","output_type":"stream"},{"name":"stderr","text":"ResNet18_SGD - Epoch 9/10 [Training]: 100%|██████████| 220/220 [00:24<00:00,  8.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"ResNet18_SGD - Epoch 9/10: Train Loss: 0.3255, Train Acc: 88.40% | Val Loss: 0.4571, Val Acc: 84.40%\n","output_type":"stream"},{"name":"stderr","text":"ResNet18_SGD - Epoch 10/10 [Training]: 100%|██████████| 220/220 [00:24<00:00,  8.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"ResNet18_SGD - Epoch 10/10: Train Loss: 0.3120, Train Acc: 89.02% | Val Loss: 0.6223, Val Acc: 79.10%\n\nFinal evaluation for variant: ResNet18_SGD\n","output_type":"stream"},{"name":"stderr","text":"Evaluating ResNet18_SGD: 100%|██████████| 47/47 [00:02<00:00, 18.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Confusion matrix saved to confusion_matrices/ResNet18_SGD_confusion_matrix.png\nClassification Report:\n              precision    recall  f1-score   support\n\n   buildings       0.58      0.95      0.72       437\n      forest       0.98      0.82      0.90       474\n     glacier       0.76      0.83      0.80       553\n    mountain       0.89      0.60      0.72       525\n         sea       0.77      0.89      0.83       510\n      street       0.93      0.65      0.76       501\n\n    accuracy                           0.79      3000\n   macro avg       0.82      0.79      0.79      3000\nweighted avg       0.82      0.79      0.79      3000\n\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}